{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eaf3c43-85c5-4462-ba1f-a70bd64f149e",
   "metadata": {},
   "source": [
    "# Tutorial MongoDB CRUD and Aggregation, <div style=\"color:red\">Module Assigment 1</div>\n",
    "\n",
    "----\n",
    "student's name: Hemanthkumar Muthusamy Gunasekaran\n",
    "\n",
    "student's email: h.muthusamy-gunasekaran@oth-aw.de\n",
    "\n",
    "----\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<div style=\"color:red\">Attention, this tutorial is an Module Assigment, it is used for grade. I refere to the module course where you should hand in this notebook with your code, description and explanations</div>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Download the mongodb server and install it on your machine.\n",
    "the notebook requires `pymongo`: `pip install pymongo`  this as well.\n",
    "\n",
    "\n",
    "Mac command for running the mongoDB Server after installing the server using brew: `brew services start mongodb/brew/mongodb-community`\n",
    "\n",
    "\n",
    "Make yourself familiar with the possibilities to access and wrangle information using pymongo and the underlying query mechanism of mongoDB. A document describing the aggregation pipeline of mongoDB is located in the moodle course.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15897b-f3f2-4dc5-b4b6-947d51df3cbf",
   "metadata": {},
   "source": [
    "#### Connection establishment\n",
    "\n",
    "Python based Connection Management, URL of server is necessary, typically `localhost`\n",
    "\n",
    "Database name: _`shopDB`_\n",
    "\n",
    "Collections are referenced using the name of the collections.\n",
    "\n",
    "Collection is created if not already existant in DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21cc433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.15.5)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pymongo) (2.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38136f9a-98b4-4e71-aebf-ccd841cf2416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:49:45.414505Z",
     "start_time": "2025-12-01T07:49:45.376311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 2, 'ok': 1.0}, acknowledged=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from datetime import datetime\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"shopDB\"]\n",
    "\n",
    "users = db[\"users\"]\n",
    "products = db[\"products\"]\n",
    "orders = db[\"orders\"]\n",
    "reviews = db[\"reviews\"]\n",
    "\n",
    "\n",
    "# Reset\n",
    "users.delete_many({})\n",
    "products.delete_many({})\n",
    "orders.delete_many({})\n",
    "reviews.delete_many({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63478668-843e-4679-b5d1-d3238b0c8de6",
   "metadata": {},
   "source": [
    "#### Database content \n",
    "some entries are added (create / inserted) to the corresponding collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7354166-e977-487a-81c3-84a668ad9e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:49:47.765995Z",
     "start_time": "2025-12-01T07:49:47.746853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Insert users\n",
    "users.insert_many([\n",
    "    {\n",
    "        \"_id\": ObjectId(\"65f100000000000000000001\"),\n",
    "        \"name\": \"Alice Müller\",\n",
    "        \"email\": \"alice@example.com\",\n",
    "        \"createdAt\": datetime(2025, 1, 10, 9, 0, 0),\n",
    "        \"address\": {\"street\": \"Main Street 1\", \"city\": \"Berlin\", \"zip\": \"10115\", \"country\": \"DE\"},\n",
    "        \"tags\": [\"premium\", \"newsletter\"],\n",
    "    },\n",
    "    {\n",
    "        \"_id\": ObjectId(\"65f100000000000000000002\"),\n",
    "        \"name\": \"Bob Schmidt\",\n",
    "        \"email\": \"bob@example.com\",\n",
    "        \"createdAt\": datetime(2025, 1, 12, 15, 30, 0),\n",
    "        \"address\": {\"street\": \"Oak Avenue 5\", \"city\": \"Hamburg\", \"zip\": \"20095\", \"country\": \"DE\"},\n",
    "        \"tags\": [\"standard\"],\n",
    "    },\n",
    "])\n",
    "\n",
    "# Insert products\n",
    "products.insert_many([\n",
    "    {\"_id\": ObjectId(\"65f200000000000000000001\"), \"name\": \"Mechanical Keyboard\",\n",
    "     \"category\": \"electronics\", \"price\": 129.99, \"stock\": 42,\n",
    "     \"tags\": [\"keyboard\", \"mechanical\", \"gaming\"], \"createdAt\": datetime(2025,1,8,10)},\n",
    "    {\"_id\": ObjectId(\"65f200000000000000000002\"), \"name\": \"Noise-Cancelling Headphones\",\n",
    "     \"category\": \"electronics\", \"price\": 199.00, \"stock\": 15,\n",
    "     \"tags\": [\"audio\",\"headphones\"], \"createdAt\": datetime(2025,1,9,11,30)},\n",
    "    {\"_id\": ObjectId(\"65f200000000000000000003\"), \"name\": \"Ergonomic Office Chair\",\n",
    "     \"category\": \"furniture\", \"price\": 299.00, \"stock\": 7,\n",
    "     \"tags\": [\"office\",\"chair\"], \"createdAt\": datetime(2025,1,11,13)},\n",
    "])\n",
    "\n",
    "# Insert orders\n",
    "orders.insert_many([\n",
    "    {\n",
    "        \"_id\": ObjectId(\"65f300000000000000000001\"),\n",
    "        \"userId\": ObjectId(\"65f100000000000000000001\"),\n",
    "        \"createdAt\": datetime(2025,1,15,10,15),\n",
    "        \"status\": \"shipped\",\n",
    "        \"items\": [\n",
    "            {\"productId\": ObjectId(\"65f200000000000000000001\"), \"nameSnapshot\": \"Mechanical Keyboard\", \"quantity\": 1, \"priceAtPurchase\": 119.99},\n",
    "            {\"productId\": ObjectId(\"65f200000000000000000002\"), \"nameSnapshot\": \"Noise-Cancelling Headphones\", \"quantity\": 1, \"priceAtPurchase\": 189.00},\n",
    "        ],\n",
    "        \"shippingAddress\": {\"street\":\"Main Street 1\",\"city\":\"Berlin\",\"zip\":\"10115\",\"country\":\"DE\"},\n",
    "        \"payment\": {\"method\":\"credit_card\",\"paid\":True,\"totalAmount\":308.99},\n",
    "    },\n",
    "    {\n",
    "        \"_id\": ObjectId(\"65f300000000000000000002\"),\n",
    "        \"userId\": ObjectId(\"65f100000000000000000002\"),\n",
    "        \"createdAt\": datetime(2025,1,16,16,45),\n",
    "        \"status\": \"processing\",\n",
    "        \"items\": [\n",
    "            {\"productId\": ObjectId(\"65f200000000000000000003\"), \"nameSnapshot\": \"Ergonomic Office Chair\", \"quantity\": 1, \n",
    "             \"priceAtPurchase\": 289.00},\n",
    "        ],\n",
    "        \"shippingAddress\": {\"street\":\"Oak Avenue 5\",\"city\":\"Hamburg\",\"zip\":\"20095\",\"country\":\"DE\"},\n",
    "        \"payment\": {\"method\":\"paypal\",\"paid\":False,\"totalAmount\":289.00},\n",
    "    },\n",
    "])\n",
    "\n",
    "# Insert reviews\n",
    "reviews.insert_many([\n",
    "    {\"_id\": ObjectId(\"65f400000000000000000001\"),\n",
    "     \"productId\": ObjectId(\"65f200000000000000000001\"),\n",
    "     \"userId\": ObjectId(\"65f100000000000000000001\"),\n",
    "     \"rating\": 5, \"title\": \"Great keyboard!\",\n",
    "     \"text\": \"Feels amazing to type, perfect for coding.\",\n",
    "     \"createdAt\": datetime(2025,1,17,9)},\n",
    "    {\"_id\": ObjectId(\"65f400000000000000000002\"),\n",
    "     \"productId\": ObjectId(\"65f200000000000000000002\"),\n",
    "     \"userId\": ObjectId(\"65f100000000000000000002\"),\n",
    "     \"rating\": 4, \"title\": \"Good sound\",\n",
    "     \"text\": \"Noise cancelling is solid, but a bit tight.\",\n",
    "     \"createdAt\": datetime(2025,1,18,14,30)},\n",
    "]\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Data inserted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce6e5f-a91d-4f93-b994-517cfa940d3d",
   "metadata": {},
   "source": [
    "Adding individual Entries are also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77782349-d806-4504-9587-6f556f7ad8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:49:51.938805Z",
     "start_time": "2025-12-01T07:49:51.934719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted new user with _id: 6935caa4d9dfbf1962f43dbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/s2j6q52d0k5c5x3kf7hlyzcr0000gn/T/ipykernel_68755/2049312822.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"createdAt\": datetime.utcnow(),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 3.1 CREATE: a User\n",
    "new_user = {\n",
    "    \"name\": \"Charlie Weber\",\n",
    "    \"email\": \"charlie@example.com\",\n",
    "    \"createdAt\": datetime.utcnow(),\n",
    "    \"address\": {\n",
    "        \"street\": \"Example St 10\",\n",
    "        \"city\": \"Munich\",\n",
    "        \"zip\": \"80331\",\n",
    "        \"country\": \"DE\",\n",
    "    },\n",
    "    \"tags\": [\"standard\"],\n",
    "}\n",
    "insert_result = users.insert_one(new_user)\n",
    "print(\"Inserted new user with _id:\", insert_result.inserted_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad4d47a-6fec-4103-974a-74750c2cdf73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:49:54.024826Z",
     "start_time": "2025-12-01T07:49:54.005425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Electronics products with price < 150:\n",
      "{'_id': ObjectId('65f200000000000000000001'), 'name': 'Mechanical Keyboard', 'category': 'electronics', 'price': 129.99, 'stock': 42, 'tags': ['keyboard', 'mechanical', 'gaming'], 'createdAt': datetime.datetime(2025, 1, 8, 10, 0)}\n",
      "\n",
      "Orders for Alice:\n",
      "{'_id': ObjectId('65f300000000000000000001'), 'userId': ObjectId('65f100000000000000000001'), 'createdAt': datetime.datetime(2025, 1, 15, 10, 15), 'status': 'shipped', 'items': [{'productId': ObjectId('65f200000000000000000001'), 'nameSnapshot': 'Mechanical Keyboard', 'quantity': 1, 'priceAtPurchase': 119.99}, {'productId': ObjectId('65f200000000000000000002'), 'nameSnapshot': 'Noise-Cancelling Headphones', 'quantity': 1, 'priceAtPurchase': 189.0}], 'shippingAddress': {'street': 'Main Street 1', 'city': 'Berlin', 'zip': '10115', 'country': 'DE'}, 'payment': {'method': 'credit_card', 'paid': True, 'totalAmount': 308.99}}\n",
      "\n",
      "Reviews for Mechanical Keyboard:\n",
      "{'_id': ObjectId('65f400000000000000000001'), 'productId': ObjectId('65f200000000000000000001'), 'userId': ObjectId('65f100000000000000000001'), 'rating': 5, 'title': 'Great keyboard!', 'text': 'Feels amazing to type, perfect for coding.', 'createdAt': datetime.datetime(2025, 1, 17, 9, 0)}\n",
      "\n",
      "Updating order status for Bob's order...\n",
      "Updated order:\n",
      " {'_id': ObjectId('65f300000000000000000002'), 'userId': ObjectId('65f100000000000000000002'), 'createdAt': datetime.datetime(2025, 1, 16, 16, 45), 'status': 'shipped', 'items': [{'productId': ObjectId('65f200000000000000000003'), 'nameSnapshot': 'Ergonomic Office Chair', 'quantity': 1, 'priceAtPurchase': 289.0}], 'shippingAddress': {'street': 'Oak Avenue 5', 'city': 'Hamburg', 'zip': '20095', 'country': 'DE'}, 'payment': {'method': 'paypal', 'paid': True, 'totalAmount': 289.0}}\n",
      "\n",
      "Increasing price of all electronics products by 10...\n",
      "{'_id': ObjectId('65f200000000000000000001'), 'name': 'Mechanical Keyboard', 'category': 'electronics', 'price': 139.99, 'stock': 42, 'tags': ['keyboard', 'mechanical', 'gaming'], 'createdAt': datetime.datetime(2025, 1, 8, 10, 0)}\n",
      "{'_id': ObjectId('65f200000000000000000002'), 'name': 'Noise-Cancelling Headphones', 'category': 'electronics', 'price': 209.0, 'stock': 15, 'tags': ['audio', 'headphones'], 'createdAt': datetime.datetime(2025, 1, 9, 11, 30)}\n",
      "\n",
      "Deleting reviews with rating <= 2 (if any)...\n",
      "Deleted count: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.2 READ: products of categoryelectronics, price < 150\n",
    "print(\"\\nElectronics products with price < 150:\")\n",
    "for doc in products.find({\"category\": \"electronics\", \"price\": {\"$lt\": 150}}):\n",
    "    print(doc)\n",
    "\n",
    "# READ: Alice's Orders  \n",
    "alice = users.find_one({\"email\": \"alice@example.com\"})\n",
    "print(\"\\nOrders for Alice:\")\n",
    "for order in orders.find({\"userId\": alice[\"_id\"]}):\n",
    "    print(order)\n",
    "\n",
    "# READ: get reviews for specific product\n",
    "keyboard = products.find_one({\"name\": \"Mechanical Keyboard\"})\n",
    "print(\"\\nReviews for Mechanical Keyboard:\")\n",
    "for review in reviews.find({\"productId\": keyboard[\"_id\"]}):\n",
    "    print(review)\n",
    "\n",
    "# 3.3 UPDATE: change order status\n",
    "print(\"\\nUpdating order status for Bob's order...\")\n",
    "orders.update_one(\n",
    "    {\"_id\": ObjectId(\"65f300000000000000000002\")},\n",
    "    {\"$set\": {\"status\": \"shipped\", \"payment.paid\": True}},\n",
    ")\n",
    "print(\"Updated order:\\n\", orders.find_one({\"_id\": ObjectId(\"65f300000000000000000002\")}))\n",
    "\n",
    "# UPDATE: Increase all elements by 10 money ;)\n",
    "print(\"\\nIncreasing price of all electronics products by 10...\")\n",
    "products.update_many(\n",
    "    {\"category\": \"electronics\"},\n",
    "    {\"$inc\": {\"price\": 10}},\n",
    ")\n",
    "for doc in products.find({\"category\": \"electronics\"}):\n",
    "    print(doc)\n",
    "\n",
    "# 3.4 DELETE\n",
    "print(\"\\nDeleting reviews with rating <= 2 (if any)...\")\n",
    "delete_result = reviews.delete_many({\"rating\": {\"$lte\": 2}})\n",
    "print(\"Deleted count:\", delete_result.deleted_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c87af-4547-45f6-970b-9aab52dd07db",
   "metadata": {},
   "source": [
    "# Task (MongoDB,  Nested Documents)\n",
    "\n",
    "<div style=\"color:orange\">Create for each task a specific python function (<code>taks1(...), task2(...), task3(...)</code>)!</div> \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:red\">Make also sure to compare your solution against the solution provided by chatgpt. Discuss overlaps or divergences of the solutions.</div>\n",
    "\n",
    "In addition to the implementation tasks, discuss where atomicity and multi-document transactions are required in this scenario (user creation, stock validation and update, order insertion).\n",
    "Briefly explain the potential consequences if no atomicity / transaction support is used (e.g. race conditions, overselling, inconsistent orders).\n",
    "Finally, provide a concrete solution that uses MongoDB transactions (via pymongo and sessions) to ensure that user handling, stock updates, and order creation are executed atomically.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Be aware to combine all subTask Functions in the last function**\n",
    "\n",
    "Implement python code to create a **new order in MongoDB** with the following requirements:\n",
    "\n",
    "\n",
    "1. **User handling (embedded user document in the order)**  <code>taks1(...)</code>\n",
    "   - The order is placed by a user identified by some unique field (e.g. `email`).  \n",
    "   - Check in the MongoDB `users` collection whether this user already exists.  \n",
    "   - If the user does **not** exist, insert a **new user document** into the `users` collection. Align the format of the new document with the previously stored documents.\n",
    "   - In the order document, embed a **nested `user` subdocument** (e.g. containing `userId`, `name`, `email`, etc.), so that user information is directly available inside the order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f0233d-30dd-48d1-8eb2-553eb1054eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1(db, session, email, user_data_if_new):\n",
    "    users_col = db[\"users\"]\n",
    "    \n",
    "    # Check if user exists\n",
    "    user = users_col.find_one({\"email\": email}, session=session)\n",
    "    \n",
    "    # Create if missing\n",
    "    if not user:\n",
    "        # Ensure the new data has the required timestamp if not provided\n",
    "        if \"createdAt\" not in user_data_if_new:\n",
    "            user_data_if_new[\"createdAt\"] = datetime.now()\n",
    "            \n",
    "        result = users_col.insert_one(user_data_if_new, session=session)\n",
    "        \n",
    "        # Fetch the complete document we just inserted to get the _id\n",
    "        user = users_col.find_one({\"_id\": result.inserted_id}, session=session)\n",
    "\n",
    "    # Create the embedded document snapshot\n",
    "    # We explicitly select fields to snapshot so the order has a permanent record of user details\n",
    "    embedded_user = {\n",
    "        \"userId\": user[\"_id\"],\n",
    "        \"name\": user[\"name\"],\n",
    "        \"email\": user[\"email\"],\n",
    "        \"address\": user[\"address\"]\n",
    "    }\n",
    "    \n",
    "    return embedded_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157372bd",
   "metadata": {},
   "source": [
    "### Task 1: User Handling\n",
    "\n",
    "**Explanation:**\n",
    "To handle the user part of the order, I first check the `users` collection to see if a user with the given email already exists. If they don't, I insert the new user data right away so every order is linked to a real profile. Finally, instead of just passing back the whole database document, I create a specific \"snapshot\" containing just the ID, name, email, and address. This ensures the order keeps a record of the address *as it was at the time of purchase*, even if the user updates it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2186745-e134-4cc7-ad44-3ad27f5cb158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:49:57.765368Z",
     "start_time": "2025-12-01T07:49:57.763345Z"
    }
   },
   "source": [
    "\n",
    "2. **Order content with embedded product descriptions**  <code>taks2(...)</code>\n",
    "   - The order must contain **at least one item**.\n",
    "   - Each item refers to a product stored in the `products` collection (e.g. via `productId`).  \n",
    "   - For each item, fetch the corresponding product from `products` and embed a **nested product description** inside the order, for example:\n",
    "     ```json\n",
    "     {\n",
    "       \"productId\": \"...\",\n",
    "       \"name\": \"...\",\n",
    "       \"priceAtPurchase\": ...,\n",
    "       \"quantity\": ...\n",
    "     }\n",
    "     ```\n",
    "   - This way, the order stores a **snapshot of the product data** at the time of purchase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c038669d-13fa-42d4-a1ac-e21b3b40afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(db, session, items_to_order):\n",
    "    products_col = db[\"products\"]\n",
    "    order_items = []\n",
    "    \n",
    "    for item in items_to_order:\n",
    "        product_id = item[\"productId\"]\n",
    "        quantity = item[\"quantity\"]\n",
    "        \n",
    "        # Fetch the current product details\n",
    "        product = products_col.find_one({\"_id\": product_id}, session=session)\n",
    "        \n",
    "        if not product:\n",
    "            # In a real app, you might raise an error here\n",
    "            print(f\"Warning: Product {product_id} not found!\")\n",
    "            continue\n",
    "            \n",
    "        # Create the snapshot\n",
    "        # We lock in the price and name NOW, so future changes don't affect this order\n",
    "        snapshot = {\n",
    "            \"productId\": product[\"_id\"],\n",
    "            \"name\": product[\"name\"],  # Snapshotting the name\n",
    "            \"priceAtPurchase\": product[\"price\"], # Snapshotting the price\n",
    "            \"quantity\": quantity\n",
    "        }\n",
    "        \n",
    "        order_items.append(snapshot)\n",
    "        \n",
    "    return order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cf0d6",
   "metadata": {},
   "source": [
    "### Task 2: Order Content (Product Snapshots)\n",
    "\n",
    "**Explanation:**\n",
    "For the order content, I needed to make sure the price and name of a product are \"locked in\" at the moment of purchase. I iterated through the list of items the user wanted to buy and fetched their current details from the `products` collection. Then, I created a list of snapshots that includes the `name` and `priceAtPurchase` right inside the order. This way, if the shop changes the price of an item next week, the old order history remains accurate and doesn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104af3f-03db-45e7-8b8c-138b76fb0461",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98488e2c-c374-4496-808b-6b3c0d9efca7",
   "metadata": {},
   "source": [
    "\n",
    "3. **Stock validation and update in MongoDB**  \n",
    "   - Before inserting the order into the `orders` collection:\n",
    "     - For each item, query the `products` collection and check whether there is **sufficient `stock`** available.  \n",
    "     - If **any** product does not have enough stock, **abort** the operation (do not insert the order, do not modify stock).  \n",
    "     - If all products have sufficient stock, **decrease the stock** in `products` for each item (e.g. using `$inc: { stock: -quantity }`).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dddc840-eacc-4a79-b847-e91638a23bbc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad4c428-ea02-4fbd-8bcd-84c225157793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3(db, session, order_items):\n",
    "    products_col = db[\"products\"]\n",
    "    \n",
    "    for item in order_items:\n",
    "        product_id = item[\"productId\"]\n",
    "        quantity = item[\"quantity\"]\n",
    "        \n",
    "        # ATOMIC CHECK & UPDATE\n",
    "        # We try to find the product AND ensure it has enough stock in one query.\n",
    "        # If stock < quantity, this update will simply do nothing (modified_count = 0).\n",
    "        result = products_col.update_one(\n",
    "            {\n",
    "                \"_id\": product_id, \n",
    "                \"stock\": {\"$gte\": quantity}  # The validation condition\n",
    "            },\n",
    "            {\n",
    "                \"$inc\": {\"stock\": -quantity} # The update action\n",
    "            },\n",
    "            session=session\n",
    "        )\n",
    "        \n",
    "        # If the DB didn't update anything, it means stock was insufficient\n",
    "        if result.modified_count == 0:\n",
    "            raise ValueError(f\"Insufficient stock for product '{item['name']}' (ID: {product_id})\")\n",
    "            \n",
    "    print(\"Stock validation passed and updates applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75679028",
   "metadata": {},
   "source": [
    "### Task 3: Stock Validation and Update\n",
    "\n",
    "**Explanation:**\n",
    "This function handles the critical job of inventory management. I iterated through every item in the proposed order and performed an \"atomic conditional update.\" This means I asked MongoDB to find the product **and** check if the stock level was high enough in a single step. If the stock was sufficient, I immediately decreased it using `$inc`. If the stock wasn't high enough, the update failed (returning a count of 0), and I raised an error. In our transaction system, this error acts as an emergency stop, canceling the whole order so we don't sell items we don't have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5972f1a-c574-4401-894f-4fddc3cb6676",
   "metadata": {},
   "source": [
    "4. **Order creation in the `orders` collection**  \n",
    "   - Only after:\n",
    "     - (a) the user has been ensured to exist (and created if necessary), and  \n",
    "     - (b) all stock levels have been validated and updated,  \n",
    "   - insert a new document into the `orders` collection.  \n",
    "   - The order document should contain:\n",
    "     - an `_id` or `orderId`,  \n",
    "     - a `createdAt` timestamp,  \n",
    "     - the embedded `user` subdocument,  \n",
    "     - an `items` array containing the embedded product descriptions with quantities,  \n",
    "     - optional payment/total fields (e.g. `totalAmount`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54439123-52df-4fa8-a54e-a39e47c2d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task4(db, session, user_doc, order_items):\n",
    "    orders_col = db[\"orders\"]\n",
    "    \n",
    "    # Calculate the total amount for the record\n",
    "    total_amount = 0.0\n",
    "    for item in order_items:\n",
    "        total_amount += item[\"priceAtPurchase\"] * item[\"quantity\"]\n",
    "    \n",
    "    # Construct the final order document\n",
    "    new_order = {\n",
    "        \"userId\": user_doc[\"userId\"], # Reference for searching\n",
    "        \"createdAt\": datetime.now(),\n",
    "        \"status\": \"processing\",\n",
    "        \"user\": user_doc,             # The Snapshot from Task 1\n",
    "        \"items\": order_items,         # The Snapshots from Task 2\n",
    "        \"payment\": {\n",
    "            \"totalAmount\": round(total_amount, 2),\n",
    "            \"method\": \"credit_card\",  # Default for this example\n",
    "            \"paid\": True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to database\n",
    "    result = orders_col.insert_one(new_order, session=session)\n",
    "    \n",
    "    return result.inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f896ce",
   "metadata": {},
   "source": [
    "### Task 4: Order Creation\n",
    "\n",
    "**Explanation:**\n",
    "This function is the final step where we actually save the order. First, I calculated the total cost by adding up the price of all the items. Then, I built the final order document by putting together the user snapshot (from Task 1) and the list of product snapshots (from Task 2). Finally, I inserted this complete document into the `orders` collection. Since this is part of our transaction, it only gets saved permanently if every other part of the process succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80c9193-356b-4b3b-82e0-b910a2de03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinationOfAllTasks(client, db, user_email, new_user_data, items_to_order):\n",
    "    \"\"\"\n",
    "    Executes the entire order workflow within an ACID transaction.\n",
    "    \"\"\"\n",
    "    # 1. Start the Session\n",
    "    with client.start_session() as session:\n",
    "        # 2. Start the Transaction\n",
    "        # Everything inside this 'with' block is atomic.\n",
    "        # If an error is raised, it auto-aborts (rollbacks).\n",
    "        with session.start_transaction():\n",
    "            try:\n",
    "                print(\"Starting Transaction...\")\n",
    "                \n",
    "                # Step A: Ensure User Exists\n",
    "                user_doc = task1(db, session, user_email, new_user_data)\n",
    "                print(f\"User processed: {user_doc['name']}\")\n",
    "                \n",
    "                # Step B: Prepare Product Snapshots\n",
    "                order_items = task2(db, session, items_to_order)\n",
    "                print(f\"Prepared {len(order_items)} items for order.\")\n",
    "                \n",
    "                # Step C: Validate and Update Stock\n",
    "                # This will RAISE an exception if stock is low, triggering a rollback\n",
    "                task3(db, session, order_items)\n",
    "                \n",
    "                # Step D: Create the Order\n",
    "                order_id = task4(db, session, user_doc, order_items)\n",
    "                \n",
    "                print(f\"Transaction Committed. Order ID: {order_id}\")\n",
    "                return order_id\n",
    "\n",
    "            except Exception as e:\n",
    "                # If any step failed, we print the error.\n",
    "                # The 'with' block automatically handles the abort/rollback.\n",
    "                print(f\"Transaction Aborted! Reason: {e}\")\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39acf7",
   "metadata": {},
   "source": [
    "### Transaction Logic (Combining All Tasks)\n",
    "\n",
    "**Explanation:**\n",
    "This function acts as the manager that ties everything together using a \"Multi-Document Transaction.\" I started a session and wrapped all the previous tasks (user creation, stock updates, order creation) inside a single transaction block. This ensures that these actions happen as one indivisible unit—either they *all* succeed, or *none* of them happen. If the stock check fails or any other error occurs, the system automatically \"rolls back\" everything, so we never end up with a broken state like money taken but no order created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdabfc79",
   "metadata": {},
   "source": [
    "### Discussion: Why We Need Atomicity\n",
    "\n",
    "**1. Where Atomicity is Required**\n",
    "In this scenario, \"placing an order\" looks like one action to the user, but under the hood, it actually requires writing data to three different places:\n",
    "* **Users Collection:** To register new customers.\n",
    "* **Products Collection:** To update inventory levels.\n",
    "* **Orders Collection:** To save the final receipt.\n",
    "\n",
    "Because these are separate steps, we need **Atomicity** to treat them as a single, all-or-nothing unit.\n",
    "\n",
    "**2. The Risks of No Atomicity**\n",
    "If we ran these steps independently without transactions, two major problems could occur:\n",
    "* **Race Conditions (Overselling):** If two customers try to buy the last item at the exact same moment, both might read the stock as \"1\" before the update happens. Both would proceed to checkout, and we would end up selling stock we don't have (negative inventory).\n",
    "* **Data Inconsistency:** If the script crashes halfway through—for example, after the stock is reduced but *before* the order is saved—the database breaks. We would have missing inventory with no record of who bought it, or new users created who never actually ordered anything.\n",
    "\n",
    "**3. Our Solution Strategy**\n",
    "To fix this, I used **MongoDB’s Multi-Document ACID Transactions**. \n",
    "* I initiated a session using `client.start_session()` and wrapped the entire logic in `session.start_transaction()`.\n",
    "* Crucially, I passed this `session` to every database operation (`insert`, `update`).\n",
    "* This setup ensures safety: if any part of the process fails (like a stock check), the transaction automatically aborts and \"rolls back\" every change, leaving the database exactly as it was before we started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d2e090e852c0d",
   "metadata": {},
   "source": [
    "## Aggregations in MongoDB\n",
    "\n",
    "We now want to apply specific aggregation operations to retrieve combined information from useser and their orders. The json file contains a larger dataset which has to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3f79559de387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:53:47.558492Z",
     "start_time": "2025-12-01T07:53:47.436776Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"shopOrders\"]\n",
    "\n",
    "with open(\"orders.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "db.users.insert_many(data[\"users\"])\n",
    "db.products.insert_many(data[\"products\"])\n",
    "db.orders.insert_many(data[\"orders\"])\n",
    "db.reviews.insert_many(data[\"reviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9b03993ca50d6",
   "metadata": {},
   "source": [
    "Example pipeline for getting mean information for order values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839fd446ca113ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:53:54.965305Z",
     "start_time": "2025-12-01T07:53:54.931363Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"avgOrderValue\": {\"$avg\": \"$payment.totalAmount\"},\n",
    "            \"minOrderValue\": {\"$min\": \"$payment.totalAmount\"},\n",
    "            \"maxOrderValue\": {\"$max\": \"$payment.totalAmount\"},\n",
    "            \"countOrders\": {\"$sum\": 1},\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "list(db.orders.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c0d6be70c07c7",
   "metadata": {},
   "source": [
    "### Get all Users, who ordered more than twice of the avarage price of an order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5aa9fa4ec13db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T07:57:35.186162Z",
     "start_time": "2025-12-01T07:57:35.164033Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    # 1: Durchschnitt berechnen\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"avgOrderValue\": { \"$avg\": \"$payment.totalAmount\" }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 2: Den Durchschnittswert in die nächste Pipelinephase übertragen\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"orders\",\n",
    "            \"pipeline\": [\n",
    "                {\n",
    "                    \"$match\": {\n",
    "                        # Filter: Bestellungen > 2 × Durchschnitt\n",
    "                        \"$expr\": {\n",
    "                            \"$gt\": [\n",
    "                                \"$payment.totalAmount\",\n",
    "                                { \"$multiply\": [ \"$$avgValue\", 2 ] }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                { \"$group\": { \"_id\": \"$userId\" } }\n",
    "            ],\n",
    "            \"as\": \"usersAboveAverage\",\n",
    "            \"let\": { \"avgValue\": \"$avgOrderValue\" }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 3: Auflösen\n",
    "    { \"$unwind\": \"$usersAboveAverage\" },\n",
    "\n",
    "    # 4: Nutzerinformationen anhängen\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"users\",\n",
    "            \"localField\": \"usersAboveAverage._id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"user\"\n",
    "        }\n",
    "    },\n",
    "    { \"$unwind\": \"$user\" },\n",
    "\n",
    "    # 5: Ausgabe formatieren\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": \"$user._id\",\n",
    "            \"name\": \"$user.name\",\n",
    "            \"email\": \"$user.email\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = list(db.orders.aggregate(pipeline))\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29feb36e7b5326f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1afc7af00aae7af7",
   "metadata": {},
   "source": [
    "## Task 1 – Count Orders per User\n",
    "For each user, determine how many orders they have placed. Sort the results in descending order based on the order count.\n",
    "\n",
    "**Expected output fields:**\n",
    "- `userId`\n",
    "- `name`\n",
    "- `orderCount`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4de7431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete: 'db_analytics' is now defined.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# 1. Connect to the Server\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "\n",
    "# 2. Define the db_analytics variable (Connecting to 'shopOrders')\n",
    "db_analytics = client[\"shopOrders\"]\n",
    "\n",
    "# 3. Reload the data (Optional but safe to ensure it exists)\n",
    "# Note: If you already loaded it successfully before, you technically only need lines 1-2.\n",
    "# But running this ensures you are starting fresh.\n",
    "db_analytics.users.delete_many({})\n",
    "db_analytics.products.delete_many({})\n",
    "db_analytics.orders.delete_many({})\n",
    "db_analytics.reviews.delete_many({})\n",
    "\n",
    "with open(\"orders.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "db_analytics.users.insert_many(data[\"users\"])\n",
    "db_analytics.products.insert_many(data[\"products\"])\n",
    "db_analytics.orders.insert_many(data[\"orders\"])\n",
    "db_analytics.reviews.insert_many(data[\"reviews\"])\n",
    "\n",
    "print(\"Setup Complete: 'db_analytics' is now defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eb9fe1beba97757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 users with orders.\n",
      "{'orderCount': 11, 'userId': '65f100000000000000000057', 'name': 'Eva Hoffmann'}\n",
      "{'orderCount': 10, 'userId': '65f100000000000000000051', 'name': 'Ines Wagner'}\n",
      "{'orderCount': 10, 'userId': '65f100000000000000000036', 'name': 'Ines Schröder'}\n",
      "{'orderCount': 9, 'userId': '65f100000000000000000019', 'name': 'Eva Becker'}\n",
      "{'orderCount': 8, 'userId': '65f100000000000000000021', 'name': 'Charlie Schmidt'}\n",
      "{'orderCount': 8, 'userId': '65f100000000000000000025', 'name': 'Alice Hoffmann'}\n",
      "{'orderCount': 7, 'userId': '65f100000000000000000042', 'name': 'Olivia Fischer'}\n",
      "{'orderCount': 7, 'userId': '65f100000000000000000055', 'name': 'Charlie Becker'}\n",
      "{'orderCount': 7, 'userId': '65f100000000000000000008', 'name': 'Lukas Hoffmann'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000027', 'name': 'Lukas Meyer'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000037', 'name': 'Hannes Schröder'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000020', 'name': 'Stefan Richter'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000054', 'name': 'Charlie Wagner'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000040', 'name': 'Hannes Wagner'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000048', 'name': 'Bob Schneider'}\n",
      "{'orderCount': 6, 'userId': '65f100000000000000000033', 'name': 'Olivia Wolf'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000029', 'name': 'Jonas Becker'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000006', 'name': 'Zoe Meyer'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000007', 'name': 'Gina Koch'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000010', 'name': 'Stefan Wagner'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000030', 'name': 'Yann Schröder'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000045', 'name': 'Olivia Schäfer'}\n",
      "{'orderCount': 5, 'userId': '65f100000000000000000060', 'name': 'Charlie Klein'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000058', 'name': 'Ines Schäfer'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000005', 'name': 'Hannes Wolf'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000023', 'name': 'Rita Müller'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000016', 'name': 'Zoe Schmidt'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000028', 'name': 'Tina Koch'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000026', 'name': 'Uwe Schäfer'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000043', 'name': 'Charlie Becker'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000001', 'name': 'Uwe Fischer'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000034', 'name': 'Alice Becker'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000053', 'name': 'Zoe Schneider'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000009', 'name': 'Mara Schneider'}\n",
      "{'orderCount': 4, 'userId': '65f100000000000000000032', 'name': 'Gina Wagner'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000003', 'name': 'Bob Müller'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000059', 'name': 'Vera Hoffmann'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000022', 'name': 'Tina Schneider'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000017', 'name': 'Mara Hoffmann'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000014', 'name': 'Tina Meyer'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000038', 'name': 'Lukas Klein'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000056', 'name': 'Tina Müller'}\n",
      "{'orderCount': 3, 'userId': '65f100000000000000000049', 'name': 'Mara Fischer'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000015', 'name': 'Mara Hoffmann'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000024', 'name': 'Zoe Koch'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000047', 'name': 'Yann Koch'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000018', 'name': 'Gina Schröder'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000044', 'name': 'Mara Schmidt'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000002', 'name': 'Eva Fischer'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000035', 'name': 'Hannes Schneider'}\n",
      "{'orderCount': 2, 'userId': '65f100000000000000000052', 'name': 'Mara Weber'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000039', 'name': 'Vera Fischer'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000004', 'name': 'Rita Wagner'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000050', 'name': 'Tina Schneider'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000013', 'name': 'Lukas Bauer'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000011', 'name': 'Zoe Schäfer'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000046', 'name': 'Eva Wagner'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000012', 'name': 'Mara Hoffmann'}\n",
      "{'orderCount': 1, 'userId': '65f100000000000000000041', 'name': 'Felix Hoffmann'}\n"
     ]
    }
   ],
   "source": [
    "# Aggregation Pipeline for Task 1\n",
    "pipeline = [\n",
    "    # 1. Group by userId and count the orders\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$userId\",\n",
    "            \"orderCount\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    # 2. Join with the 'users' collection to get the name\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"users\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"userInfo\"\n",
    "        }\n",
    "    },\n",
    "    # 3. Flatten the userInfo array (lookup returns a list)\n",
    "    {\n",
    "        \"$unwind\": \"$userInfo\"\n",
    "    },\n",
    "    # 4. Sort by orderCount (descending)\n",
    "    {\n",
    "        \"$sort\": {\"orderCount\": -1}\n",
    "    },\n",
    "    # 5. Format the output to match requirements\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"userId\": \"$_id\",\n",
    "            \"name\": \"$userInfo.name\",\n",
    "            \"orderCount\": 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute and print\n",
    "results = list(db_analytics.orders.aggregate(pipeline))\n",
    "\n",
    "print(f\"Found {len(results)} users with orders.\")\n",
    "for user in results:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb206d1",
   "metadata": {},
   "source": [
    "Task 1: Count Orders per User\n",
    "\n",
    "Explanation: To find out who orders the most, I started by grouping the orders by userId and counting them. Since the order documents only have the user's ID, I had to use $lookup to join with the users collection and grab the actual names. Finally, I sorted the results in descending order so the most active users appear at the top of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f382aef1ab8eb26",
   "metadata": {},
   "source": [
    "## Task 2 – Average Order Value\n",
    "Compute the average total order value across all orders.\n",
    "Additionally, include the minimum and maximum order value found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583b209d9adc1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Order Statistics ---\n",
      "Average Order Value: 868.71 €\n",
      "Lowest Order Value:  11.53 €\n",
      "Highest Order Value: 3691.32 €\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for Task 2\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$group\": {\n",
    "            # _id: None means \"Group everything into one single bucket\"\n",
    "            \"_id\": None,\n",
    "            \"averageValue\": {\"$avg\": \"$payment.totalAmount\"},\n",
    "            \"minValue\": {\"$min\": \"$payment.totalAmount\"},\n",
    "            \"maxValue\": {\"$max\": \"$payment.totalAmount\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run the aggregation\n",
    "stats = list(db_analytics.orders.aggregate(pipeline))\n",
    "\n",
    "if stats:\n",
    "    # formatting the output to look nice\n",
    "    data = stats[0]\n",
    "    print(f\"--- Order Statistics ---\")\n",
    "    print(f\"Average Order Value: {data['averageValue']:.2f} €\")\n",
    "    print(f\"Lowest Order Value:  {data['minValue']:.2f} €\")\n",
    "    print(f\"Highest Order Value: {data['maxValue']:.2f} €\")\n",
    "else:\n",
    "    print(\"No orders found to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27878eaf",
   "metadata": {},
   "source": [
    "### Task 2: Average Order Value\n",
    "\n",
    "**Explanation:**\n",
    "For this task, I needed statistics for the entire store, not specific users. By setting the group `_id` to `None`, I told MongoDB to treat the entire `orders` collection as one single group. Then, I simply applied the `$avg`, `$min`, and `$max` operators to the `totalAmount` field to get the global figures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2baae3b9b5670",
   "metadata": {},
   "source": [
    "## Task 3 – Product Revenue Ranking\n",
    "For each product, calculate the total revenue generated.\n",
    "\n",
    "**Definition:**\n",
    "```\n",
    "revenue = SUM(quantity × priceAtPurchase)\n",
    "```\n",
    "\n",
    "Sort products by total revenue in descending order.\n",
    "\n",
    "**Expected output fields:**\n",
    "\n",
    "- `productId`\n",
    "- `name`\n",
    "- `totalRevenue`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "456bb3ed69969b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 5 Products by Revenue ---\n",
      "Desk Lamp: 20776.82 €\n",
      "USB-C Hub: 18518.41 €\n",
      "Wireless Mouse: 17331.17 €\n",
      "Desk Lamp: 17324.11 €\n",
      "Wireless Mouse: 13530.81 €\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for Task 3\n",
    "pipeline = [\n",
    "    # 1. Break the 'items' array into individual documents\n",
    "    # Before: One order with 3 items\n",
    "    # After:  3 documents, each with one item\n",
    "    {\n",
    "        \"$unwind\": \"$items\"\n",
    "    },\n",
    "    # 2. Calculate revenue per product\n",
    "    # We group by the productId found inside the item\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$items.productId\",\n",
    "            \"totalRevenue\": {\n",
    "                \"$sum\": {\n",
    "                    \"$multiply\": [\"$items.quantity\", \"$items.priceAtPurchase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # 3. Get the product name (Join with products collection)\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"products\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"productDetails\"\n",
    "        }\n",
    "    },\n",
    "    # 4. Flatten the lookup result array\n",
    "    {\n",
    "        \"$unwind\": \"$productDetails\"\n",
    "    },\n",
    "    # 5. Sort by highest revenue first\n",
    "    {\n",
    "        \"$sort\": {\"totalRevenue\": -1}\n",
    "    },\n",
    "    # 6. Format the output\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"productId\": \"$_id\",\n",
    "            \"name\": \"$productDetails.name\",\n",
    "            \"totalRevenue\": 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run the pipeline\n",
    "revenue_ranking = list(db_analytics.orders.aggregate(pipeline))\n",
    "\n",
    "print(f\"--- Top 5 Products by Revenue ---\")\n",
    "for prod in revenue_ranking[:5]:\n",
    "    print(f\"{prod['name']}: {prod['totalRevenue']:.2f} €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8dd88",
   "metadata": {},
   "source": [
    "### Task 3: Product Revenue Ranking\n",
    "\n",
    "**Explanation:**\n",
    "Since products are stored inside an array within each order, I couldn't sum up the revenue immediately. I used `$unwind` first to break the arrays apart into individual item documents. After that, I calculated the total revenue for each item (`quantity` × `price`) and grouped them by `productId`. A final lookup added the readable product names before sorting them by highest revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cff687ee29a410",
   "metadata": {},
   "source": [
    "## Task 4 – User Classification by Spending Behavior\n",
    "Classify each user based on their *average* order value.\n",
    "\n",
    "**Categories:**\n",
    "- `\"low\"`: < 100 EUR\n",
    "- `\"medium\"`: 100–300 EUR\n",
    "- `\"high\"`: > 300 EUR\n",
    "\n",
    "**Expected output fields:**\n",
    "- `_id`\n",
    "- `name`\n",
    "- `avgOrderValue`\n",
    "- `category`\n",
    "\n",
    "---\n",
    "\n",
    "Attention - possible you have to adjust the category boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da5496e13cf4d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- User Classifications (First 5) ---\n",
      "User: Zoe Schäfer\n",
      "  Avg Spend: 90.31 €\n",
      "  Category:  low\n",
      "------------------------------\n",
      "User: Charlie Becker\n",
      "  Avg Spend: 1491.02 €\n",
      "  Category:  high\n",
      "------------------------------\n",
      "User: Lukas Hoffmann\n",
      "  Avg Spend: 1139.65 €\n",
      "  Category:  high\n",
      "------------------------------\n",
      "User: Mara Hoffmann\n",
      "  Avg Spend: 673.25 €\n",
      "  Category:  high\n",
      "------------------------------\n",
      "User: Yann Schröder\n",
      "  Avg Spend: 1199.41 €\n",
      "  Category:  high\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for Task 4\n",
    "pipeline = [\n",
    "    # 1. Calculate the average order value per user\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$userId\",\n",
    "            \"avgOrderValue\": {\"$avg\": \"$payment.totalAmount\"}\n",
    "        }\n",
    "    },\n",
    "    # 2. Get the user's name\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"users\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"userInfo\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$unwind\": \"$userInfo\"\n",
    "    },\n",
    "    # 3. Classify the user based on the calculated average\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 1,\n",
    "            \"name\": \"$userInfo.name\",\n",
    "            \"avgOrderValue\": 1,\n",
    "            \"category\": {\n",
    "                \"$switch\": {\n",
    "                    \"branches\": [\n",
    "                        # Case 1: Less than 100\n",
    "                        {\"case\": {\"$lt\": [\"$avgOrderValue\", 100]}, \"then\": \"low\"},\n",
    "                        # Case 2: Less than 300 (Technically 100-300, since <100 is already caught)\n",
    "                        {\"case\": {\"$lt\": [\"$avgOrderValue\", 300]}, \"then\": \"medium\"}\n",
    "                    ],\n",
    "                    # Case 3: Everything else (Greater than 300)\n",
    "                    \"default\": \"high\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute\n",
    "user_categories = list(db_analytics.orders.aggregate(pipeline))\n",
    "\n",
    "print(f\"--- User Classifications (First 5) ---\")\n",
    "for user in user_categories[:5]:\n",
    "    print(f\"User: {user['name']}\")\n",
    "    print(f\"  Avg Spend: {user['avgOrderValue']:.2f} €\")\n",
    "    print(f\"  Category:  {user['category']}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787a549",
   "metadata": {},
   "source": [
    "### Task 4: User Classification\n",
    "\n",
    "**Explanation:**\n",
    "The goal here was to tag users based on their spending habits. First, I grouped by `userId` to calculate their average order value. Then, inside the `$project` stage, I used a `$switch` operator (which works like an if-else statement) to assign a category: \"low\" for under 100€, \"medium\" for up to 300€, and \"high\" for anything above that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26d3c1801e7ed5",
   "metadata": {},
   "source": [
    "## Task 5 – Top 3 Users per Product Category by Spending\n",
    "For each product category, determine the top 3 users ranked by total spending within that category.\n",
    "\n",
    "**Rules:**\n",
    "1. Join orders with products to determine the categories involved.\n",
    "2. Compute the total spending per user per category\n",
    "   (`quantity × priceAtPurchase` summed across all orders).\n",
    "3. For each category, return the top three highest-spending users.\n",
    "\n",
    "**Expected output structure example:**\n",
    "```json\n",
    "{\n",
    "  \"category\": \"electronics\",\n",
    "  \"topUsers\": [\n",
    "    { \"userId\": \"...\", \"name\": \"...\", \"totalSpent\": 542.90 },\n",
    "    { \"userId\": \"...\", \"name\": \"...\", \"totalSpent\": 301.50 },\n",
    "    { \"userId\": \"...\", \"name\": \"...\", \"totalSpent\": 199.99 }\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7187dbf8-5cfd-4f97-bc0b-38100a475a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Category: BOOKS ---\n",
      "1. Eva Becker: 799.49 €\n",
      "2. Eva Hoffmann: 573.17 €\n",
      "3. Charlie Klein: 554.81 €\n",
      "\n",
      "--- Category: ELECTRONICS ---\n",
      "1. Charlie Klein: 4262.75 €\n",
      "2. Lukas Hoffmann: 4152.11 €\n",
      "3. Olivia Fischer: 3599.29 €\n",
      "\n",
      "--- Category: FURNITURE ---\n",
      "1. Eva Hoffmann: 4187.32 €\n",
      "2. Eva Becker: 4166.81 €\n",
      "3. Alice Becker: 3442.39 €\n",
      "\n",
      "--- Category: GAMING ---\n",
      "1. Charlie Schmidt: 1377.83 €\n",
      "2. Hannes Wagner: 1157.23 €\n",
      "3. Yann Schröder: 896.82 €\n",
      "\n",
      "--- Category: KITCHEN ---\n",
      "1. Ines Schröder: 4189.67 €\n",
      "2. Eva Hoffmann: 2046.76 €\n",
      "3. Hannes Wolf: 2013.45 €\n",
      "\n",
      "--- Category: OFFICE ---\n",
      "1. Eva Hoffmann: 272.73 €\n",
      "2. Alice Hoffmann: 268.62 €\n",
      "3. Ines Wagner: 232.35 €\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for Task 5\n",
    "pipeline = [\n",
    "    # 1. Break down orders into individual items\n",
    "    { \"$unwind\": \"$items\" },\n",
    "\n",
    "    # 2. Get the category for each item (Join with products)\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"products\",\n",
    "            \"localField\": \"items.productId\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"productInfo\"\n",
    "        }\n",
    "    },\n",
    "    { \"$unwind\": \"$productInfo\" },\n",
    "\n",
    "    # 3. Calculate spend per User per Category\n",
    "    # We group by *both* Category and UserId to get individual user totals\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"category\": \"$productInfo.category\",\n",
    "                \"userId\": \"$userId\"\n",
    "            },\n",
    "            \"totalSpent\": {\n",
    "                \"$sum\": { \"$multiply\": [\"$items.quantity\", \"$items.priceAtPurchase\"] }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 4. Sort by highest spend first\n",
    "    # This ensures that when we group them next, the big spenders are at the top\n",
    "    { \"$sort\": { \"totalSpent\": -1 } },\n",
    "\n",
    "    # 5. Get the User's Name (Join with users)\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"users\",\n",
    "            \"localField\": \"_id.userId\",\n",
    "            \"foreignField\": \"_id\",\n",
    "            \"as\": \"userInfo\"\n",
    "        }\n",
    "    },\n",
    "    { \"$unwind\": \"$userInfo\" },\n",
    "\n",
    "    # 6. Group by Category and collect the top 3 users\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$_id.category\",\n",
    "            \"topUsers\": {\n",
    "                \"$push\": {\n",
    "                    \"userId\": \"$_id.userId\",\n",
    "                    \"name\": \"$userInfo.name\",\n",
    "                    \"totalSpent\": \"$totalSpent\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # 7. Keep only the top 3 and format the output\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"category\": \"$_id\",\n",
    "            \"topUsers\": { \"$slice\": [\"$topUsers\", 3] } # The 'Limit' trick for arrays\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Optional: Sort categories alphabetically for cleaner output\n",
    "    { \"$sort\": { \"category\": 1 } }\n",
    "]\n",
    "\n",
    "# Execute\n",
    "category_rankings = list(db_analytics.orders.aggregate(pipeline))\n",
    "\n",
    "# Print Results\n",
    "for cat_data in category_rankings:\n",
    "    print(f\"--- Category: {cat_data['category'].upper()} ---\")\n",
    "    for i, user in enumerate(cat_data['topUsers'], 1):\n",
    "        print(f\"{i}. {user['name']}: {user['totalSpent']:.2f} €\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09028d",
   "metadata": {},
   "source": [
    "### Task 5: Top 3 Users per Category\n",
    "\n",
    "**Explanation:**\n",
    "This required a few steps because the category info isn't in the order itself.\n",
    "1. I unwound the items and looked up the `products` collection to get the category for every item sold.\n",
    "2. I grouped the data by **both** `category` and `userId` to calculate exactly how much each person spent in each specific category.\n",
    "3. After sorting these results to put the big spenders on top, I grouped by category again and used `$slice` to keep only the top 3 users for each one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
